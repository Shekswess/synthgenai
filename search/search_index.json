{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"SynthGenAI Documentation \ud83d\udcda","text":"<p> Making Synthetic Data Easy </p> <p>Welcome to the SynthGenAI documentation. SynthGenAI is a package for generating synthetic datasets using LLMs. This documentation will guide you through the installation, usage, and examples of how to use SynthGenAI.</p>"},{"location":"#overview","title":"Overview \ud83e\uddd0","text":"<p>SynthGenAI is designed to be modular and can be easily extended to include different API providers for LLMs and new features.</p>"},{"location":"#why-synthgenai","title":"Why SynthGenAI? \ud83e\udd14","text":"<p>Interest in synthetic data generation has surged recently, driven by the growing recognition of data as a critical asset in AI development. Synthetic data generation addresses challenges by allowing us to create diverse and useful datasets using current pre-trained Large Language Models (LLMs).</p>"},{"location":"#tools-used-for-building-synthgenai","title":"Tools used for building SynthGenAI \ud83e\uddf0","text":"<p>The package is built using Python and the following libraries:</p> <ul> <li>uv</li> <li>LiteLLM</li> <li>Langfuse</li> <li>Pydantic</li> <li>Huggingface Hub &amp; Datasets</li> </ul>"},{"location":"#contributing","title":"Contributing \ud83e\udd1d","text":"<p>If you want to contribute to this project and make it better, your help is very welcome. Create a pull request with your changes and I will review it. If you have any questions, open an issue.</p>"},{"location":"#license","title":"License \ud83d\udcdd","text":"<p>This project is licensed under the MIT License - see the LICENSE.txt file for details.</p>"},{"location":"configurations/","title":"LLM Configuration \ud83e\udd16","text":"<p>To configure the LLMs for generating datasets, you need to create an <code>LLMConfig</code> object. This object contains the configuration for the LLM model, including the model name, temperature, top_p, and max_tokens.</p>"},{"location":"configurations/#example","title":"Example \ud83d\udcd6","text":"<pre><code>from synthgenai import LLMConfig\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\", # Check LiteLLM docs for more info\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n    api_base=\"https://api.example.com\",\n    api_key=\"your_api_key\"\n)\n</code></pre>"},{"location":"configurations/#parameters","title":"Parameters \ud83c\udf9b","text":"<ul> <li><code>model</code> (str): The name of the model to use. This should be in the format <code>model_provider/model_name</code>. (Required)</li> <li><code>temperature</code> (float): The temperature to use for the model. This controls the randomness of the generated text. Must be between 0.0 and 1.0. (Optional, default: None)</li> <li><code>top_p</code> (float): The top_p value to use for the model. This controls the nucleus sampling. Must be between 0.0 and 1.0. (Optional, default: None)</li> <li><code>max_tokens</code> (int): The maximum number of tokens to generate. Must be greater than 1000. (Optional, default: None)</li> <li><code>api_base</code> (AnyUrl): The API base URL for the LLM service. (Optional, default: None)</li> <li><code>api_key</code> (str): The API key for authenticating with the LLM service. (Optional, default: None)</li> </ul> <p>For more information on the available models and their configurations, refer to the LiteLLM documentation.</p>"},{"location":"configurations/dataset_configuration/","title":"Dataset Configuration \ud83d\udcda","text":"<p>To configure the datasets for generation, you need to create a <code>DatasetConfig</code> object. This object contains the configuration for the dataset, including the topic, domains, language, additional description, and the number of entries.</p>"},{"location":"configurations/dataset_configuration/#example","title":"Example \ud83d\udcd6","text":"<pre><code>from synthgenai import DatasetConfig\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n</code></pre>"},{"location":"configurations/dataset_configuration/#parameters","title":"Parameters \ud83c\udf9b","text":"<ul> <li><code>topic</code> (str): The topic of the dataset. (Required)</li> <li><code>domains</code> (list[str]): A list of domains related to the dataset. Must contain at least one item. (Required)</li> <li><code>language</code> (str): The language of the dataset. Default is \"English\". (Optional)</li> <li><code>additional_description</code> (str): Any additional description for the dataset. Maximum length is 1000 characters. (Optional, default: \"\")</li> <li><code>num_entries</code> (int): The number of entries to generate. Must be greater than 1. (Optional, default: 1000)</li> </ul> <p>For more information on configuring datasets, refer to the SynthGenAI documentation.</p>"},{"location":"configurations/dataset_generator_configuration/","title":"Dataset Generator Configuration \ud83c\udfed","text":"<p>To configure the dataset generator, you need to create a <code>DatasetGeneratorConfig</code> object. This object contains the configuration for both the dataset and the LLM model.</p>"},{"location":"configurations/dataset_generator_configuration/#example","title":"Example \ud83d\udcd6","text":"<pre><code>from synthgenai import DatasetConfig, LLMConfig, DatasetGeneratorConfig\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n    api_base=\"https://api.example.com\",\n    api_key=\"your_api_key\"\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    dataset_config=dataset_config,\n    llm_config=llm_config\n)\n</code></pre>"},{"location":"configurations/dataset_generator_configuration/#parameters","title":"Parameters \ud83c\udf9b","text":"<ul> <li><code>dataset_config</code> (DatasetConfig): The configuration for the dataset. (Required)</li> <li><code>llm_config</code> (LLMConfig): The configuration for the LLM. (Required)</li> </ul> <p>For more information on configuring the dataset generator, refer to the SynthGenAI documentation.</p>"},{"location":"contributing/","title":"Contributing \ud83e\udd1d","text":"<p>If you want to contribute to this project and make it better, your help is very welcome. Create a pull request with your changes and I will review it. If you have any questions, open an issue.</p>"},{"location":"contributing/#how-to-contribute-i","title":"How to Contribute \u2139\ufe0f","text":"<ol> <li>Fork the repository</li> <li>Create a new branch (<code>git checkout -b feature-branch</code>)</li> <li>Make your changes</li> <li>Commit your changes (<code>git commit -m 'Add some feature'</code>)</li> <li>Push to the branch (<code>git push origin feature-branch</code>)</li> <li>Open a pull request</li> </ol>"},{"location":"datasets/","title":"Dataset Types \ud83d\udcda","text":"<p>Currently, there are six types of datasets that can be generated using SynthGenAI:</p> <ul> <li>Raw Datasets</li> <li>Instruction Datasets</li> <li>Preference Datasets</li> <li>Sentiment Analysis Datasets</li> <li>Summarization Datasets</li> <li>Text Classification Datasets</li> </ul> <p>The datasets can be generated:</p> <ul> <li>Synchronously - each dataset entry is generated one by one</li> <li>Asynchronously - batch of dataset entries is generated at once</li> </ul>"},{"location":"datasets/instruction_datasets/","title":"Instruction Datasets \ud83d\udcac","text":"<p>To generate an Instruction dataset, you need to use the <code>InstructionDatasetGenerator</code> class. </p> <pre><code>from synthgenai import InstructionDatasetGenerator\n</code></pre> <p>Example of generated entry for the instruction dataset:</p> <pre><code>{\n  \"keyword\": \"keyword\",\n  \"topic\": \"topic\",\n  \"language\": \"language\",\n  \"generated_entry\": {\n    \"messages\": [\n      {\n        \"role\": \"system\",\n        \"content\": \"generated system(instruction) prompt\"\n      },\n      {\n        \"role\": \"user\",\n        \"content\": \"generated user prompt\"\n      },\n      {\n        \"role\": \"assistant\",\n        \"content\": \"generated assistant prompt\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"datasets/instruction_datasets/#synchronous-generation","title":"Synchronous Generation \ud83d\udd01","text":"<pre><code>import os\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    InstructionDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the InstructionDatasetGenerator\ninstruction_dataset_generator = InstructionDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset\ninstruction_dataset = instruction_dataset_generator.generate_dataset()\n</code></pre>"},{"location":"datasets/instruction_datasets/#asynchronous-generation","title":"Asynchronous Generation \ud83d\udd00","text":"<pre><code>import os\nimport asyncio\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    InstructionDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the InstructionDatasetGenerator\ninstruction_dataset_generator = InstructionDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset asynchronously\ninstruction_dataset = asyncio.run(instruction_dataset_generator.agenerate_dataset())\n</code></pre>"},{"location":"datasets/preference_datasets/","title":"Preference Datasets \ud83c\udf1f","text":"<p>To generate a Preference dataset, you need to use the <code>PreferenceDatasetGenerator</code> class.</p> <pre><code>from synthgenai import PreferenceDatasetGenerator\n</code></pre> <p>Example of generated entry for the preference dataset:</p> <pre><code>{\n  \"keyword\": \"keyword\",\n  \"topic\": \"topic\",\n  \"language\": \"language\",\n  \"generated_entry\": {\n    \"prompt\": [\n      { \"role\": \"system\", \"content\": \"generated system(instruction) prompt\" },\n      { \"role\": \"user\", \"content\": \"generated user prompt\" }\n    ],\n    \"chosen\": [\n      { \"role\": \"assistant\", \"content\": \"generated chosen assistant response\" }\n    ],\n    \"rejected\": [\n      {\n        \"role\": \"assistant\",\n        \"content\": \"generated rejected assistant response\"\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"datasets/preference_datasets/#synchronous-generation","title":"Synchronous Generation \ud83d\udd01","text":"<pre><code>import os\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    PreferenceDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the PreferenceDatasetGenerator\npreference_dataset_generator = PreferenceDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset\npreference_dataset = preference_dataset_generator.generate_dataset()\n</code></pre>"},{"location":"datasets/preference_datasets/#asynchronous-generation","title":"Asynchronous Generation \ud83d\udd00","text":"<pre><code>import os\nimport asyncio\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    PreferenceDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the PreferenceDatasetGenerator\npreference_dataset_generator = PreferenceDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset asynchronously\npreference_dataset = asyncio.run(preference_dataset_generator.agenerate_dataset())\n</code></pre>"},{"location":"datasets/raw_datasets/","title":"Raw Datasets \ud83e\udd69","text":"<p>To generate a Raw dataset, you need to use the <code>RawDatasetGenerator</code> class.</p> <pre><code>from synthgenai import RawDatasetGenerator\n</code></pre> <p>Example of generated entry for the raw dataset:</p> <pre><code>{\n  \"keyword\": \"keyword\",\n  \"topic\": \"topic\",\n  \"language\": \"language\",\n  \"generated_entry\": {\n    \"text\": \"generated text\"\n  }\n}\n</code></pre>"},{"location":"datasets/raw_datasets/#synchronous-generation","title":"Synchronous Generation \ud83d\udd01","text":"<pre><code>import os\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    RawDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the RawDatasetGenerator\nraw_dataset_generator = RawDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset\nraw_dataset = raw_dataset_generator.generate_dataset()\n</code></pre>"},{"location":"datasets/raw_datasets/#asynchronous-generation","title":"Asynchronous Generation \ud83d\udd00","text":"<pre><code>import os\nimport asyncio\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    RawDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the RawDatasetGenerator\nraw_dataset_generator = RawDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset asynchronously\nraw_dataset = asyncio.run(raw_dataset_generator.agenerate_dataset())\n</code></pre>"},{"location":"datasets/sentiment_analysis_datasets/","title":"Sentiment Analysis Datasets \ud83c\udfad","text":"<p>To generate a Sentiment Analysis dataset, you need to use the <code>SentimentAnalysisDatasetGenerator</code> class.</p> <pre><code>from synthgenai import SentimentAnalysisDatasetGenerator\n</code></pre> <p>Example of generated entry for the sentiment analysis dataset:</p> <pre><code>{\n  \"keyword\": \"keyword\",\n  \"topic\": \"topic\",\n  \"language\": \"language\",\n  \"generated_entry\": {\n    \"prompt\": \"generated text\",\n    \"label\": \"generated sentiment (which can be positive, negative, neutral)\"\n  }\n}\n</code></pre>"},{"location":"datasets/sentiment_analysis_datasets/#synchronous-generation","title":"Synchronous Generation \ud83d\udd01","text":"<pre><code>import os\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    SentimentAnalysisDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the SentimentAnalysisDatasetGenerator\nsentiment_analysis_dataset_generator = SentimentAnalysisDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset\nsentiment_analysis_dataset = sentiment_analysis_dataset_generator.generate_dataset()\n</code></pre>"},{"location":"datasets/sentiment_analysis_datasets/#asynchronous-generation","title":"Asynchronous Generation \ud83d\udd00","text":"<pre><code>import os\nimport asyncio\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    SentimentAnalysisDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the SentimentAnalysisDatasetGenerator\nsentiment_analysis_dataset_generator = SentimentAnalysisDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset asynchronously\nsentiment_analysis_dataset = asyncio.run(sentiment_analysis_dataset_generator.agenerate_dataset())\n</code></pre>"},{"location":"datasets/summarization_datasets/","title":"Summarization Datasets \ud83e\uddfe","text":"<p>To generate a Summarization dataset, you need to use the <code>SummarizationDatasetGenerator</code> class.</p> <pre><code>from synthgenai import SummarizationDatasetGenerator\n</code></pre> <p>Example of generated entry for the summarization dataset:</p> <pre><code>{\n  \"keyword\": \"keyword\",\n  \"topic\": \"topic\",\n  \"language\": \"language\",\n  \"generated_entry\": {\n    \"text\": \"generated text\",\n    \"summary\": \"generated summary\"\n  }\n}\n</code></pre>"},{"location":"datasets/summarization_datasets/#synchronous-generation","title":"Synchronous Generation \ud83d\udd01","text":"<pre><code>import os\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    SummarizationDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the SummarizationDatasetGenerator\nsummarization_dataset_generator = SummarizationDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset\nsummarization_dataset = summarization_dataset_generator.generate_dataset()\n</code></pre>"},{"location":"datasets/summarization_datasets/#asynchronous-generation","title":"Asynchronous Generation \ud83d\udd00","text":"<pre><code>import os\nimport asyncio\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    SummarizationDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the SummarizationDatasetGenerator\nsummarization_dataset_generator = SummarizationDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset asynchronously\nsummarization_dataset = asyncio.run(summarization_dataset_generator.agenerate_dataset())\n</code></pre>"},{"location":"datasets/text_classification_datasets/","title":"Text Classification Datasets \ud83d\udd20","text":"<p>To generate a Text Classification dataset, you need to use the <code>TextClassificationDatasetGenerator</code> class.</p> <pre><code>from synthgenai import TextClassificationDatasetGenerator\n</code></pre> <p>Example of generated entry for the text classification dataset:</p> <pre><code>{\n  \"keyword\": \"keyword\",\n  \"topic\": \"topic\",\n  \"language\": \"language\",\n  \"generated_entry\": {\n    \"prompt\": \"generated text\",\n    \"label\": \"generated sentiment (which will be from a list of labels, created from the model)\"\n  }\n}\n</code></pre>"},{"location":"datasets/text_classification_datasets/#synchronous-generation","title":"Synchronous Generation \ud83d\udd01","text":"<pre><code>import os\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    TextClassificationDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the TextClassificationDatasetGenerator\ntext_classification_dataset_generator = TextClassificationDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset\ntext_classification_dataset = text_classification_dataset_generator.generate_dataset()\n</code></pre>"},{"location":"datasets/text_classification_datasets/#asynchronous-generation","title":"Asynchronous Generation \ud83d\udd00","text":"<pre><code>import os\nimport asyncio\nfrom synthgenai import (\n    DatasetConfig,\n    DatasetGeneratorConfig,\n    LLMConfig,\n    TextClassificationDatasetGenerator,\n)\n\n# Setting the API keys\nos.environ[\"LLM_API_KEY\"] = \"\"\n\n# Creating the LLMConfig\nllm_config = LLMConfig(\n    model=\"model_provider/model_name\",\n    temperature=0.5,\n    top_p=0.9,\n    max_tokens=2048,\n)\n\n# Creating the DatasetConfig\ndataset_config = DatasetConfig(\n    topic=\"topic_name\",\n    domains=[\"domain1\", \"domain2\"],\n    language=\"English\",\n    additional_description=\"Additional description\",\n    num_entries=1000\n)\n\n# Creating the DatasetGeneratorConfig\ndataset_generator_config = DatasetGeneratorConfig(\n    llm_config=llm_config,\n    dataset_config=dataset_config,\n)\n\n# Creating the TextClassificationDatasetGenerator\ntext_classification_dataset_generator = TextClassificationDatasetGenerator(dataset_generator_config)\n\n# Generating the dataset asynchronously\ntext_classification_dataset = asyncio.run(text_classification_dataset_generator.agenerate_dataset())\n</code></pre>"},{"location":"examples/","title":"Examples \ud83d\udcd6","text":""},{"location":"examples/#examples-by-llm-api-providers","title":"Examples by LLM API Providers \ud83e\udd16","text":"API Provider Example File Anthropic anthropic_instruction_dataset_example.py Azure AI azure_ai_preference_dataset_example.py Azure azure_summarization_dataset_example.py Bedrock bedrock_raw_dataset_example.py Gemini gemini_langfuse_raw_dataset_example.py Groq groq_preference_dataset_example.py Hugging Face huggingface_instruction_dataset_example.py Mistral mistral_preference_dataset_example.py Ollama ollama_preference_dataset_example.py OpenAI openai_raw_dataset_example.py SageMaker sagemaker_summarization_dataset_example.py Vertex AI vertex_ai_text_classification_dataset_example.py vLLM vllm_sentiment_analysis_dataset_example.py"},{"location":"examples/#examples-by-dataset-types","title":"Examples by Dataset Types \ud83d\udcda","text":"Dataset Type Example File Instruction Dataset anthropic_instruction_dataset_example.py, huggingface_instruction_dataset_example.py Preference Dataset azure_ai_preference_dataset_example.py, groq_preference_dataset_example.py, mistral_preference_dataset_example.py, ollama_preference_dataset_example.py Raw Dataset bedrock_raw_dataset_example.py, gemini_langfuse_raw_dataset_example.py, openai_raw_dataset_example.py Sentiment Analysis vllm_sentiment_analysis_dataset_example.py Summarization Dataset azure_summarization_dataset_example.py, sagemaker_summarization_dataset_example.py Text Classification vertex_ai_text_classification_dataset_example.py"},{"location":"installation/","title":"Installation \ud83d\udee0\ufe0f","text":"<p>To install the package, you can use the following command:</p> <pre><code>pip install synthgenai\n</code></pre> <p>or you can install the package directly from the source code using the following command:</p> <pre><code>git clone https://github.com/Shekswess/synthgenai.git\nuv build\npip install ./dist/synthgenai-{version}-py3-none-any.whl\n</code></pre>"},{"location":"installation/#requirements","title":"Requirements \ud83d\udccb","text":"<p>To use the package, you need to have the following requirements installed:</p> <ul> <li>Python 3.10+</li> <li>uv for building the package directly from the source code</li> <li>Ollama running on your local machine if you want to use Ollama as an API provider (optional)</li> <li>Langfuse running on your local machine or in the cloud if you want to use Langfuse for tracebility (optional)</li> <li>Hugging Face Hub account if you want to save the generated datasets on Hugging Face Hub with generated token (optional)</li> </ul>"},{"location":"llm_providers/","title":"Supported LLM Providers \ud83d\udcaa","text":"<p>The available API providers for LLMs are:</p> <ul> <li>Groq - more info about Groq models that can be used and how they can be used, can be found here</li> <li>Mistral AI - more info about Mistral AI models that can be used and how they can be used, can be found here</li> <li>Gemini - more info about Gemini models that can be used and how they can be used, can be found here</li> <li>Bedrock - more info about Bedrock models that can be used and how they can be used, can be found here</li> <li>Anthropic - more info about Anthropic models that can be used and how they can be used, can be found here</li> <li>OpenAI - more info about OpenAI models that can be used, and how they can be used, can be found here</li> <li>Hugging Face - more info about Hugging Face models that can be used, and how they can be used, can be found here</li> <li>Ollama - more info about Ollama models that can be used, and how they can be used, can be found here</li> <li>vLLM - more info about vLLM models that can be used and how they can be used, can be found here</li> <li>SageMaker - more info about SageMaker models that can be used and how they can be used, can be found here</li> <li>Azure - more info about Azure and Azure AI models that can be used and how they can be used, can be found here &amp; here</li> <li>Vertex AI - more info about Vertex AI models that can be used and how they can be used, can be found here</li> </ul>"},{"location":"ui/","title":"Quick Start \ud83d\ude80","text":"<p>To quickly start using the SynthGenAI, you need to have the package installed. You can install it using the following command:</p> <pre><code>pip install synthgenai\n</code></pre> <p>After installation, simply run the following command in your terminal:</p> <pre><code>synthgenai\n</code></pre> <p>This will launch the Gradio UI for generating synthetic datasets.</p> <p> Gradio UI for generating synthetic datasets </p> <p>To create datasets, you need to set up the following fields in the UI:</p> <ul> <li>LLM Model: The LLM model to use (e.g., model_provider/model_name).</li> <li>Temperature: The temperature for the LLM.</li> <li>Top P: The top_p value for the LLM.</li> <li>Max Tokens: The maximum number of tokens for the LLM.</li> <li>API Base: The API base URL (optional).</li> <li>API Key: The API key (optional).</li> <li>Dataset Type: The type of dataset to generate (e.g., Raw, Instruction, Preference, Sentiment Analysis, Summarization, Text Classification).</li> <li>Topic: The topic of the dataset.</li> <li>Domains: The domains for the dataset (comma-separated).</li> <li>Language: The language of the dataset.</li> <li>Additional Description: Additional description for the dataset (optional).</li> <li>Number of Entries: The number of entries in the dataset.</li> <li>Hugging Face Token: The Hugging Face token.</li> <li>Hugging Face Repo Name: The Hugging Face repository name.</li> <li>LLM Environment Variables: Comma-separated environment variables for the LLM (e.g., KEY1=VALUE1, KEY2=VALUE2).</li> </ul>"}]}